{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3d6046-5eb5-4f62-8f3f-36e7e0c92fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Biddls/Onion_News\")\n",
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c982dbd0-5015-462c-94aa-4201ffc01b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Relaxed Marie Kondo Now Says She Perfectly Happy Living In Waist-High Sewage',\n",
       " 'U.S. Officials Call For Correct Amount Of Violence',\n",
       " 'Kamala Harris Asks Communications Assistant If She Can Take Them Out For Coffee And Pick Their Brain Sometime',\n",
       " '25 Arrested In Fake Nursing School Diploma Scheme',\n",
       " 'World’s Oldest American Dies At 72',\n",
       " 'Report: Everyone Laughing At What Is A Very Silly Misunderstanding, But Don’t Be Fooled—Even Now, The Seeds Of Resentment Are Taking Root',\n",
       " 'CEOs Explain How They Will Use ChatGPT',\n",
       " 'FDA Moves To Ease Blood Donation Rules For Gay And Bisexual Men',\n",
       " 'Study Shows Humans Still Have Genes To Grow Full Coat Of Body Hair',\n",
       " 'Look What Happens When You Leave A McDonald’s Hamburger Out On A Counter For A Year']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEP = '#~#'\n",
    "\n",
    "def get_headline(text):\n",
    "    return text.split(SEP)[0].strip()\n",
    "\n",
    "headlines = [get_headline(ds['train'][i]['text']) for i in range(10)]\n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336eed47-1283-4b0a-97d5-bc8e1e537e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relaxed Marie Kondo Now Says She Perfectly Happy Living In Waist-High Sewage\n",
      "[('Perfectly Happy Living', np.float64(0.0032173869679631944)), ('Relaxed Marie Kondo', np.float64(0.0035308295728302113))]\n",
      "\n",
      "U.S. Officials Call For Correct Amount Of Violence\n",
      "[('Officials Call', np.float64(0.012602360123953448)), ('Amount Of Violence', np.float64(0.012602360123953448))]\n",
      "\n",
      "Kamala Harris Asks Communications Assistant If She Can Take Them Out For Coffee And Pick Their Brain Sometime\n",
      "[('Harris Asks Communications', np.float64(0.02140921543860024)), ('Communications Assistant', np.float64(0.02140921543860024))]\n",
      "\n",
      "25 Arrested In Fake Nursing School Diploma Scheme\n",
      "[('School Diploma Scheme', np.float64(0.001881309737406442)), ('Fake Nursing School', np.float64(0.0032173869679631944))]\n",
      "\n",
      "World’s Oldest American Dies At 72\n",
      "[('Oldest American Dies', np.float64(0.0032173869679631944)), ('Oldest American', np.float64(0.02140921543860024))]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "\n",
    "kw_extractor = yake.KeywordExtractor(lan='en', n=3, top=2)\n",
    "\n",
    "for headline in headlines[:5]:\n",
    "    print(headline)\n",
    "    print(kw_extractor.extract_keywords(headline))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbe7463b-53d4-40fe-90bb-add97b32a7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[relaxed marie kondo, waist-high sewage]\n",
      "[u.s. officials, correct amount, violence]\n",
      "[kamala harris, communications assistant, their brain, coffee]\n",
      "[fake nursing school diploma scheme]\n",
      "[]\n",
      "[a very silly misunderstanding, resentment, the seeds, report, root]\n",
      "[chatgpt, ceos]\n",
      "[fda, blood donation rules, gay and bisexual men]\n",
      "[full coat, body hair, humans, study, genes]\n",
      "[a mcdonald’s hamburger, a counter, a year]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(headlines[0])\n",
    "\n",
    "def extract_topics(text, max_topics=2):\n",
    "    doc = nlp(text.lower()) # lower casing the text seems to result in better parsing\n",
    "    noun_chunks = [chunk for chunk in doc.noun_chunks if chunk.root.pos_ != 'PRON'] # get all noun chunks, ignoring pronouns\n",
    "    noun_chunks.sort(key=key, reverse=True)\n",
    "    return noun_chunks\n",
    "\n",
    "def key(span):\n",
    "    # Returns the importance of a span. A span is important if it contains an entity or is long.\n",
    "    entity_types = ['PERSON', 'ORG', 'GPE']\n",
    "    is_entity = any(token.ent_type_ in entity_types for token in span)\n",
    "    length = len(span.text.strip())\n",
    "    return (is_entity, length)\n",
    "\n",
    "for headline in headlines:\n",
    "    print(extract_topics(headline))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
